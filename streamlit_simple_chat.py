import os
import streamlit as st
from typing import List, Dict, Tuple
from dotenv import load_dotenv

try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # Allow the app to render a helpful error if package missing


PAGE_TITLE = "ç°¡æ˜“AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼ˆæ‰‹ç¶šãèª¬æ˜ã‚’æœ€åˆã«è¡¨ç¤ºï¼‰"
DEFAULT_SYSTEM_PROMPT_PATH = "prompts/system_prompt.txt"


RULES_BUBBLE_TEXT = """ã€æ‰‹ç¶šã¨ãƒ«ãƒ¼ãƒ«ã®ã”æ¡ˆå†…ã€‘

æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦è©•ä¾¡ã‚’è¡Œã„ã¾ã™ï¼š

**è©•ä¾¡åŸºæº–**
- 5é …ç›®ï¼ˆå­¦æ¥­æˆç¸¾ã€ç ”ç©¶èƒ½åŠ›ã€ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—ã€å°†æ¥æ€§ï¼‰ã®åŠ é‡å¹³å‡
- ç·åˆåˆ¤å®šï¼šã‚ãªãŸã®é‡ã¿é…åˆ† + å‚åŠ è€…è©•ä¾¡è€…2åã®å¤šæ•°æ±º

**é‡è¦ãªåˆ¶ç´„**
- AIã¯çµæœã‚’å¤‰æ›´ã§ãã¾ã›ã‚“
- èª¤èª­ãƒ»è¦‹è½ã¨ã—ãŒã‚ã‚Œã°ç•°è­°ç”³ã—ç«‹ã¦ã§ç¢ºèªã—ã¾ã™
- ã™ã¹ã¦ã®è©•ä¾¡æ ¹æ‹ ã‚’é€æ˜ã«é–‹ç¤ºã—ã¾ã™

**ä»Šå¾Œã®æµã‚Œ**
1. ã‚ãªãŸã®é‡è¦–ç‚¹ã®ç¢ºèª
2. åˆæ ¼ãƒ»ä¸åˆæ ¼ã®è¦³ç‚¹æ•´ç†ã¨è³ªå•ãƒ»ç•°è­°æ©Ÿä¼š
3. æœ€çµ‚çµæœã®è¦ç´„
"""


def get_system_prompt() -> str:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’.envã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®šã«ã‚‚å¯¾å¿œï¼‰"""
    # .env ã®èª­ã¿è¾¼ã¿
    load_dotenv()

    # å„ªå…ˆåº¦: SYSTEM_PROMPT_FILE > SYSTEM_PROMPT
    file_path = os.getenv("SYSTEM_PROMPT_FILE")
    if file_path and os.path.exists(file_path):
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            pass

    # æ—¢å®šã®åŒæ¢±ãƒ•ã‚¡ã‚¤ãƒ«
    if os.path.exists(DEFAULT_SYSTEM_PROMPT_PATH):
        try:
            with open(DEFAULT_SYSTEM_PROMPT_PATH, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            pass

    env_prompt = os.getenv("SYSTEM_PROMPT")
    if env_prompt and env_prompt.strip():
        return env_prompt

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    return (
        "ã‚ãªãŸã¯åˆå¦åˆ¤æ–­ã®åˆæ„å½¢æˆã‚’æ”¯æ´ã™ã‚‹AIãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ã§ã™ã€‚"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é‡è¦–ç‚¹ã¨2åã®å‚åŠ è€…ã®è¦³ç‚¹ã‚’è¸ã¾ãˆã€ç°¡æ½”ã«çŠ¶æ³æ•´ç†ã—ã€1ã¤ã®è³ªå•ã®ã¿ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
    )


def _init_state():
    if "system_text" not in st.session_state:
        st.session_state.system_text = get_system_prompt()

    if "weights" not in st.session_state:
        # æ—¢å®šå€¤ï¼ˆä¾‹ï¼‰
        st.session_state.weights = {
            "å­¦æ¥­æˆç¸¾": 30,
            "ç ”ç©¶èƒ½åŠ›": 25,
            "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³": 20,
            "ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—": 10,
            "å°†æ¥æ€§": 15,
        }

    if "messages" not in st.session_state:
        # 1) æœ€åˆã®å¹ãå‡ºã—ï¼šãƒ«ãƒ¼ãƒ«æ¡ˆå†…
        msgs = [{"role": "assistant", "content": RULES_BUBBLE_TEXT}]

        # 2) æ¬¡ã®å¹ãå‡ºã—ï¼šé‡ã¿é…åˆ†ç¢ºèªã¨è³ªå•ï¼ˆLLMã«ã¯é€ã‚‰ãªã„ï¼‰
        w = st.session_state.weights
        # ä¸Šä½2é …ç›®
        top = sorted(w.items(), key=lambda kv: kv[1], reverse=True)[:2]
        top_criteria = [top[0][0], top[1][0]] if len(top) >= 2 else [top[0][0], ""]
        weights_text = (
            "ã€ã‚ãªãŸã®é‡è¦–ç‚¹ã«ã¤ã„ã¦ã€‘\n\n"
            "UIã§è¨­å®šã•ã‚ŒãŸé‡ã¿é…åˆ†ã‚’ç¢ºèªã—ã¾ã—ãŸï¼š\n"
            f"- å­¦æ¥­æˆç¸¾: {w['å­¦æ¥­æˆç¸¾']}%\n"
            f"- ç ”ç©¶èƒ½åŠ›: {w['ç ”ç©¶èƒ½åŠ›']}%  \n"
            f"- ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³: {w['ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³']}%\n"
            f"- ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—: {w['ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—']}%\n"
            f"- å°†æ¥æ€§: {w['å°†æ¥æ€§']}%\n\n"
            f"ã‚ãªãŸãŒç‰¹ã«{top_criteria[0]}ã‚’é‡è¦–ã•ã‚Œã‚‹ç†ç”±ã«ã¤ã„ã¦ã€è©³ã—ããŠèã‹ã›ãã ã•ã„ã€‚\n"
            "ã“ã®å­¦ç”Ÿã®è©•ä¾¡ã«ãŠã„ã¦ãªãœã“ã‚Œã‚‰ã®é …ç›®ã‚’é‡è¦ã¨è€ƒãˆã‚‰ã‚ŒãŸã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ\n\n"
            "ãªãŠã€å‚åŠ è€…è©•ä¾¡è€…2åã‚‚ãã‚Œãã‚Œç•°ãªã‚‹åŸºæº–ã‚’æŒã£ã¦è©•ä¾¡ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚"
        )
        msgs.append({"role": "assistant", "content": weights_text})

        st.session_state.messages = msgs


def _get_openai_client():
    # .env ã‚’èª­ã¿è¾¼ã‚“ã§ã‹ã‚‰ã‚­ãƒ¼ã‚’å‚ç…§
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY ãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    if OpenAI is None:
        raise RuntimeError("openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚requirements ã«è¿½åŠ ã—ã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
    return OpenAI(api_key=api_key)


def _build_responses_input(messages: List[Dict], system_text: str):
    # OpenAI Responses API ã® input å½¢å¼ã«å¤‰æ›
    input_seq = [
        {
            "role": "system",
            # Responses API ã¯ 'text' ã§ã¯ãªã 'input_text' ã‚’è¦æ±‚
            "content": [{"type": "input_text", "text": system_text}]
        }
    ]
    # å‹•çš„ãªæ„æ€æ±ºå®šãƒ‡ãƒ¼ã‚¿ï¼ˆUIã®é‡ã¿ç­‰ï¼‰ã‚’ system ã§è¿½åŠ 
    w = st.session_state.get("weights", {})
    decision_data_json = (
        '{\n'
        '  "student_info": {\n'
        '    "name": "ç”°ä¸­å¤ªéƒ",\n'
        '    "student_id": "S2024001",\n'
        '    "scores": {\n'
        '      "å­¦æ¥­æˆç¸¾": 85,\n'
        '      "ç ”ç©¶èƒ½åŠ›": 78,\n'
        '      "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³": 82,\n'
        '      "ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—": 65,\n'
        '      "å°†æ¥æ€§": 79\n'
        '    }\n'
        '  },\n'
        '  "user_weights": {\n'
        f'    "å­¦æ¥­æˆç¸¾": {w.get("å­¦æ¥­æˆç¸¾", 30)},\n'
        f'    "ç ”ç©¶èƒ½åŠ›": {w.get("ç ”ç©¶èƒ½åŠ›", 25)},\n'
        f'    "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³": {w.get("ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³", 20)},\n'
        f'    "ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—": {w.get("ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—", 10)},\n'
        f'    "å°†æ¥æ€§": {w.get("å°†æ¥æ€§", 15)}\n'
        '  },\n'
        '  "user_decision": "åˆæ ¼",\n'
        '  "participant_decisions": {\n'
        '    "participant1": {\n'
        '      "decision": "ä¸åˆæ ¼",\n'
        '      "weights": {\n'
        '        "ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—": 40,\n'
        '        "ç·åˆãƒãƒ©ãƒ³ã‚¹": 30,\n'
        '        "å­¦æ¥­æˆç¸¾": 15,\n'
        '        "ç ”ç©¶èƒ½åŠ›": 10,\n'
        '        "å°†æ¥æ€§": 5\n'
        '      }\n'
        '    },\n'
        '    "participant2": {\n'
        '      "decision": "ä¸åˆæ ¼",\n'
        '      "weights": {\n'
        '        "å­¦æ¥­æˆç¸¾": 35,\n'
        '        "ç ”ç©¶èƒ½åŠ›": 30,\n'
        '        "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³": 20,\n'
        '        "ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—": 10,\n'
        '        "å°†æ¥æ€§": 5\n'
        '      }\n'
        '    }\n'
        '  }\n'
        '}\n'
    )
    input_seq.append({
        "role": "system",
        "content": [{"type": "input_text", "text": "# ç”Ÿå¾’/æ„æ€æ±ºå®šãƒ‡ãƒ¼ã‚¿\n" + decision_data_json}]
    })
    # æœ€åˆã®2ã¤ã® assistant ãƒãƒ–ãƒ«ï¼ˆãƒ«ãƒ¼ãƒ«æ¡ˆå†… + é‡ã¿ç¢ºèªï¼‰ã¯ç”»é¢è¡¨ç¤ºå°‚ç”¨ã€‚LLMã¸ã¯æŠ•å…¥ã—ãªã„ã€‚
    for idx, m in enumerate(messages):
        if idx in (0, 1) and m.get("role") == "assistant":
            continue
        role = m["role"]
        # user/system ã¯ 'input_text'ã€assistant ã¯éå»å‡ºåŠ›ã¨ã—ã¦ 'output_text'
        content_type = "output_text" if role == "assistant" else "input_text"
        input_seq.append({
            "role": role,
            "content": [{"type": content_type, "text": m["content"]}]
        })
    return input_seq


def _call_llm(client: "OpenAI", messages: List[Dict], system_text: str, model: str = "gpt-4.1") -> str:
    input_payload = _build_responses_input(messages, system_text)
    resp = client.responses.create(
        model=model,
        input=input_payload,
        temperature=0.4,
        max_output_tokens=1024,
        top_p=1
    )
    # SDK v1.35+ ã¯ output_text ã‚’æä¾›
    text = getattr(resp, "output_text", None)
    if text:
        return text
    # å¿µã®ç‚ºã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    try:
        return resp.output[0].content[0].text  # type: ignore[attr-defined]
    except Exception:
        return str(resp)


def main():
    st.set_page_config(page_title=PAGE_TITLE, page_icon="ğŸ¤–", layout="centered")
    st.title(PAGE_TITLE)

    _init_state()

    with st.expander("ç’°å¢ƒè¨­å®š", expanded=False):
        st.write(".env ã‹ã‚‰ OPENAI_API_KEYãƒ»SYSTEM_PROMPT ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        model = st.text_input("ãƒ¢ãƒ‡ãƒ«", value="gpt-4.1", help="OpenAI Responses API å¯¾å¿œãƒ¢ãƒ‡ãƒ«å")

    with st.sidebar:
        st.subheader("é‡ã¿è¨­å®šï¼ˆåˆè¨ˆ100%ï¼‰")
        w = st.session_state.weights
        col1, col2 = st.columns(2)
        with col1:
            w_gaku = st.number_input("å­¦æ¥­æˆç¸¾", min_value=0, max_value=100, value=int(w["å­¦æ¥­æˆç¸¾"]))
            w_com = st.number_input("ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³", min_value=0, max_value=100, value=int(w["ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³"]))
            w_fut = st.number_input("å°†æ¥æ€§", min_value=0, max_value=100, value=int(w["å°†æ¥æ€§"]))
        with col2:
            w_ken = st.number_input("ç ”ç©¶èƒ½åŠ›", min_value=0, max_value=100, value=int(w["ç ”ç©¶èƒ½åŠ›"]))
            w_lead = st.number_input("ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—", min_value=0, max_value=100, value=int(w["ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—"]))

        total = w_gaku + w_ken + w_com + w_lead + w_fut
        st.caption(f"ç¾åœ¨ã®åˆè¨ˆ: {total}%")
        apply_btn = st.button("é‡ã¿ã‚’é©ç”¨ã—ã¦ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ")
        if apply_btn:
            st.session_state.weights = {
                "å­¦æ¥­æˆç¸¾": int(w_gaku),
                "ç ”ç©¶èƒ½åŠ›": int(w_ken),
                "ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³": int(w_com),
                "ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—": int(w_lead),
                "å°†æ¥æ€§": int(w_fut),
            }
            # åˆæœŸ2ãƒãƒ–ãƒ«ã‚’æœ€æ–°ã®é‡ã¿ã§å†ç”Ÿæˆã€å±¥æ­´ã¯ç ´æ£„
            if "messages" in st.session_state:
                del st.session_state["messages"]
            st.experimental_rerun()

    # æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æç”»
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # å…¥åŠ›æ¬„
    user_input = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›...")
    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        try:
            client = _get_openai_client()
            assistant_text = _call_llm(client, st.session_state.messages, st.session_state.system_text, model=model)
        except Exception as e:
            assistant_text = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

        st.session_state.messages.append({"role": "assistant", "content": assistant_text})
        with st.chat_message("assistant"):
            st.markdown(assistant_text)


if __name__ == "__main__":
    main()
