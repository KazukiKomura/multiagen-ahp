"""
AI Chat routes (LangGraph-free version).
Streamlitã® `streamlit_simple_chat.py` ã¨åŒç­‰ã®å¹ãå‡ºã—ãƒ»ã‚„ã‚Šå–ã‚Šã«çµ±ä¸€ã€‚
åˆæœŸ2ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é™çš„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¹ãå‡ºã—ã€ãã®å¾Œã¯ Responses API ã§å¿œç­”ã€‚
"""

import os
from flask import Blueprint, request, jsonify, session
from ..repository.session_repository import session_repository
from ..utils import argumentation_engine  # è«–ç†ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from typing import List, Dict, Any
import json

try:
    from openai import OpenAI
except Exception:  # pragma: no cover - runtime guard
    OpenAI = None

ai_chat_bp = Blueprint('ai_chat', __name__)


# ===== Streamlitã¨åŒç­‰ã®æŒ¯ã‚‹èˆã„ã‚’ã™ã‚‹ãŸã‚ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====
RULES_BUBBLE_TEXT = (
    "ã€æ‰‹ç¶šã¨ãƒ«ãƒ¼ãƒ«ã®ã”æ¡ˆå†…ã€‘\n\n"
    "æœ¬ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦è©•ä¾¡ã‚’è¡Œã„ã¾ã™ï¼š\n\n"
    "**è©•ä¾¡åŸºæº–**\n"
    "- 5é …ç›®ï¼ˆå­¦æ¥­æˆç¸¾ã€åŸºç¤èƒ½åŠ›ãƒ†ã‚¹ãƒˆã€å®Ÿè·µçµŒé¨“ã€æ¨è–¦ãƒ»è©•ä¾¡ã€å­¦æ­´ãƒ»æ‰€å±ï¼‰ã®åŠ é‡å¹³å‡\n"
    "- ç·åˆåˆ¤å®šï¼šã‚ãªãŸã®é‡ã¿é…åˆ† + AI 3åã®å¤šæ•°æ±ºï¼ˆä¸€æ¬¡é€šé/è¦‹é€ã‚Šï¼‰\n\n"
    "**é‡è¦ãªåˆ¶ç´„**\n"
    "- AIã¯çµæœã‚’å¤‰æ›´ã§ãã¾ã›ã‚“\n"
    "- èª¤èª­ãƒ»è¦‹è½ã¨ã—ãŒã‚ã‚Œã°ç•°è­°ç”³ã—ç«‹ã¦ã§ç¢ºèªã—ã¾ã™\n"
    "- ã™ã¹ã¦ã®è©•ä¾¡æ ¹æ‹ ã‚’é€æ˜ã«é–‹ç¤ºã—ã¾ã™\n\n"
    "**ä»Šå¾Œã®æµã‚Œ**\n"
    "1. ã‚ãªãŸã®é‡è¦–ç‚¹ã®ç¢ºèª\n"
    "2. ä¸€æ¬¡é€šéãƒ»è¦‹é€ã‚Šã®è¦³ç‚¹æ•´ç†ã¨è³ªå•ãƒ»ç•°è­°æ©Ÿä¼š\n"
    "3. æœ€çµ‚çµæœã®è¦ç´„\n"
)


def _get_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or OpenAI is None:
        raise RuntimeError("OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆAPIã‚­ãƒ¼/ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèªï¼‰")
    return OpenAI(api_key=api_key)


def _create_openai_client_with_key(api_key: str):
    if not api_key or OpenAI is None:
        raise RuntimeError("OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆAPIã‚­ãƒ¼/ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèªï¼‰")
    return OpenAI(api_key=api_key)


def _get_system_prompt() -> str:
    # prompts/system_prompt.txt > env SYSTEM_PROMPT > fallback
    default_path = os.path.join(os.getcwd(), "prompts", "system_prompt.txt")
    if os.path.exists(default_path):
        try:
            with open(default_path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            pass
    env_prompt = os.getenv("SYSTEM_PROMPT")
    if env_prompt and env_prompt.strip():
        return env_prompt
    return (
        "ã‚ãªãŸã¯ä¸€æ¬¡é¸è€ƒåˆ¤æ–­ã®åˆæ„å½¢æˆã‚’æ”¯æ´ã™ã‚‹AIãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ã‚¿ã§ã™ã€‚"
        "ã‚ãªãŸã®é‡è¦–ç‚¹ï¼ˆå­¦æ¥­æˆç¸¾ãƒ»åŸºç¤èƒ½åŠ›ãƒ†ã‚¹ãƒˆãƒ»å®Ÿè·µçµŒé¨“ãƒ»æ¨è–¦ãƒ»è©•ä¾¡ãƒ»å­¦æ­´ãƒ»æ‰€å±ï¼‰ã¨"
        "3åã®AIã®è¦³ç‚¹ã‚’è¸ã¾ãˆã€ç°¡æ½”ã«çŠ¶æ³æ•´ç†ã—ã€1ã¤ã®è³ªå•ã®ã¿ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
    )


def _sanitize_llm_context(ctx: Dict[str, Any]) -> Dict[str, Any]:
    """LLMå…¥åŠ›ç”¨ã«ä¸è¦/ç§˜åŒ¿ã‚­ãƒ¼ã‚’é™¤å»ã—ãŸãƒ‡ã‚£ãƒ¼ãƒ—ã‚³ãƒ”ãƒ¼ã‚’è¿”ã™ã€‚

    é™¤å¤–ã‚­ãƒ¼ï¼ˆãƒã‚¹ãƒˆå†…ã‚‚å¯¾è±¡ï¼‰:
      - questionnaire, algorithm_type, reason, condition, session_id
    """
    EXCLUDE = {"questionnaire", "algorithm_type", "reason", "condition", "session_id"}

    def _clean(obj):
        if isinstance(obj, dict):
            out = {}
            for k, v in obj.items():
                if k in EXCLUDE:
                    continue
                out[k] = _clean(v)
            return out
        if isinstance(obj, list):
            return [_clean(x) for x in obj]
        return obj

    try:
        return _clean(dict(ctx))
    except Exception:
        return {k: v for k, v in (ctx or {}).items() if k not in EXCLUDE}


def _display_label(name: str) -> str:
    """UIè¡¨ç¤ºç”¨ã®åŸºæº–åãƒãƒƒãƒ”ãƒ³ã‚°ã€‚"""
    try:
        return 'å­¦æ­´ãƒ»æ‰€å±' if name == 'å¿—æœ›å‹•æ©Ÿãƒ»ãƒ•ã‚£ãƒƒãƒˆ' else name
    except Exception:
        return name


def _build_initial_messages(weights: Dict[str, int], context: Dict[str, Any] = None) -> List[Dict[str, str]]:
    """
    åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰ï¼ˆargumentation_engine.pyã®åˆ†æçµæœã‚’ç›´æ¥ä½¿ç”¨ï¼‰
    """
    weights = weights or {}

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã¯è«–ç†ã‚¨ãƒ³ã‚¸ãƒ³ã‚’å®Ÿè¡Œã—ã¦åˆ†æçµæœã‚’å–å¾—
    if context:
        try:
            import src.utils.argumentation_engine as argumentation_engine

            print(f"[DEBUG] åˆæœŸãƒãƒ–ãƒ«ç”Ÿæˆ: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç¢ºèª")
            print(f"  - ã‚ãªãŸã®åˆ¤æ–­: {context.get('user_initial_decision')}")
            print(f"  - ã‚ãªãŸã®é‡ã¿: {context.get('user_initial_weights')}")
            print(f"  - å‚åŠ è€…æ„è¦‹æ•°: {len(context.get('participant_opinions', []))}")

            # è«–ç†ã‚¨ãƒ³ã‚¸ãƒ³ã‚’å®Ÿè¡Œï¼ˆai_chat.pyã¨åŒã˜æµã‚Œï¼‰
            arguments = argumentation_engine.extract_atomic_arguments(context)
            attacks = argumentation_engine.determine_attacks(arguments)
            user_weights = context.get('user_initial_weights') or context.get('user_final_weights') or {}

            print(f"[DEBUG] æŠ½å‡ºã•ã‚ŒãŸä¸»å¼µæ•°: {len(arguments)}")
            print(f"[DEBUG] æ”»æ’ƒé–¢ä¿‚æ•°: {len(attacks)}")

            if user_weights:
                debate_summary = argumentation_engine.summarize_debate(arguments, attacks, user_weights)
            else:
                debate_summary = argumentation_engine.summarize_debate(arguments, attacks)

            print(f"[DEBUG] ä½¿ç”¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : {debate_summary.get('algorithm_type', 'legacy')}")

            # æ–°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®è©³ç´°åˆ†æçµæœã‚’ä½¿ç”¨
            if debate_summary.get('algorithm_type') == 'two_track_ranking_salience':
                detailed_analysis = debate_summary.get('detailed_analysis', {})
                conflict_points = detailed_analysis.get('conflict_points', [])
                analysis_overview = detailed_analysis.get('analysis_overview', {})
                user_claim_summary = detailed_analysis.get('user_claim_summary', '')

                # ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ã‚’ã€Œã‚ãªãŸã€ã«å¤‰æ›
                user_claim_summary = user_claim_summary.replace('ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯', 'ã‚ãªãŸã¯').replace('ãƒ¦ãƒ¼ã‚¶ãƒ¼', 'ã‚ãªãŸ')

                print(f"[DEBUG] æ¤œå‡ºã•ã‚ŒãŸå¯¾ç«‹ç‚¹æ•°: {len(conflict_points)}")

                lines = [
                    "## ğŸ“Š è­°è«–çŠ¶æ³ã®åˆ†æ\n\n",
                    f"**{user_claim_summary}**\n\n",
                    f"**AI**: {analysis_overview.get('total_participants', 3)}åã®è©•ä¾¡è€…ï¼ˆã‚ãªãŸã¨ã®ä¾¡å€¤è¦³ã®è¿‘ã•ã§åˆ†é¡ï¼‰\n",
                    f"**å¯¾ç«‹è«–ç‚¹**: {analysis_overview.get('conflict_points_found', 0)}ä»¶ã®ä¸»è¦ãªé•ã„\n\n"
                ]

                # ä¾¡å€¤è¦³ã®ç¾¤åˆ†ã‘ã‚’è¡¨ç¤º
                participant_opinions = context.get('participant_opinions', [])
                if participant_opinions:
                    lines.append("### ğŸ¯ å„AIã®åˆ¤æ–­\n")
                    for opinion in participant_opinions:
                        bot_id = opinion.get('bot_id', 0)
                        participant_name = f"AI{bot_id + 1}"
                        decision = opinion.get('decision', 'ä¸æ˜')
                        weights_info = opinion.get('weights', {})

                        if weights_info:
                            top_criterion = max(weights_info, key=weights_info.get, default='ä¸æ˜')
                            top_weight = weights_info.get(top_criterion, 0)

                            user_decision = context.get('user_initial_decision', 'ä¸€æ¬¡é€šé')
                            agreement = "âœ… ã‚ãªãŸã¨åŒã˜åˆ¤æ–­" if decision == user_decision else "âŒ ã‚ãªãŸã¨ç•°ãªã‚‹åˆ¤æ–­"

                            lines.append(f"- **{participant_name}**: {decision} {agreement}\n")
                            lines.append(f"  æœ€é‡è¦–: {_display_label(top_criterion)}ï¼ˆ{top_weight}%ï¼‰\n")

                    lines.append("\n")

                # è«–ç‚¹è©³ç´°ã‚’è¡¨ç¤ºï¼ˆæŠ€è¡“çš„æƒ…å ±ã‚’é™¤å»ï¼‰
                if conflict_points:
                    lines.append("### ğŸ” æ³¨ç›®ã™ã¹ãé•ã„\n")
                    for i, point in enumerate(conflict_points, 1):
                        # ãƒ‡ãƒ¼ã‚¿ã‚’å®‰å…¨ã«å–å¾—
                        criterion = _display_label(point.get('criterion', 'ä¸æ˜'))
                        user_weight = point.get('user_weight', 0)
                        opponent_weight = point.get('opponent_weight', 0)

                        # opponentæƒ…å ±ã‚’å–å¾—
                        opponent_info = point.get('top_opponent', {})
                        opponent_source = opponent_info.get('source', 'participant1')
                        opponent_claim = opponent_info.get('claim', 'ä¸æ˜')

                        # participant1 â†’ AI1 ã«å¤‰æ›
                        opponent_name = opponent_source.replace('participant', 'AI')

                        # ã‚°ãƒ«ãƒ¼ãƒ—ãƒ©ãƒ™ãƒ«ã‚’ç›¸å¯¾çš„åˆ†å‰²ã«åˆã‚ã›ã¦å¤‰æ›
                        group_label = point.get('group', 'ä¸æ˜ãªç¾¤')
                        if group_label == 'ä¾¡å€¤è¦³ãŒè¿‘ã„ç¾¤':
                            group_explanation = f'ã‚ãªãŸã«æœ€ã‚‚è¿‘ã„ä¾¡å€¤è¦³ã‚’æŒã¤AI'
                        elif group_label == 'ä¾¡å€¤è¦³ãŒç•°ãªã‚‹ç¾¤':
                            group_explanation = f'ã‚ãªãŸã¨ç•°ãªã‚‹ä¾¡å€¤è¦³ã‚’æŒã¤AI'
                        else:
                            group_explanation = group_label.replace('ä¾¡å€¤è¦³ãŒè¿‘ã„ç¾¤', 'è¿‘ã„ä¾¡å€¤è¦³ã®AI').replace('ä¾¡å€¤è¦³ãŒç•°ãªã‚‹ç¾¤', 'ç•°ãªã‚‹ä¾¡å€¤è¦³ã®AI')

                        lines.extend([
                            f"**é•ã„{i}: {criterion}ã¸ã®è©•ä¾¡**\n",
                            f"- ã‚ãªãŸ: {context.get('user_initial_decision', 'ä¸€æ¬¡é€šé')}ï¼ˆ{user_weight}%é‡è¦–ï¼‰\n",
                            f"- {opponent_name}: {opponent_claim}ï¼ˆ{opponent_weight}%é‡è¦–ï¼‰\n",
                            f"- é–¢ä¿‚: {group_explanation}\n\n"
                        ])

                lines.extend([
                    "---\n\n",
                    "ä¸Šè¨˜ã®çŠ¶æ³ã‚’è¸ã¾ãˆã¦ã€**ã‚ãªãŸã®åˆ¤æ–­ç†ç”±**ã‚’ãŠèã‹ã›ãã ã•ã„ã€‚\n",
                    "ç‰¹ã«åŒã˜ã‚ˆã†ãªä¾¡å€¤è¦³ã®äººã¨åˆ¤æ–­ãŒåˆ†ã‹ã‚ŒãŸç‚¹ã«ã¤ã„ã¦ã€ã©ã®ã‚ˆã†ãªè€ƒãˆã§æ±ºã‚ã‚‰ã‚ŒãŸã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ"
                ])

                initial_text = ''.join(lines)
                print(f"[DEBUG] åˆæœŸãƒãƒ–ãƒ«ç”Ÿæˆå®Œäº†ï¼ˆæ–°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ä½¿ç”¨ï¼‰")

                return [{"role": "assistant", "content": initial_text}]

            else:
                # æ—¢å­˜ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®çµæœã‚’ä½¿ç”¨
                print(f"[DEBUG] æ—¢å­˜ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®çµæœã‚’ä½¿ç”¨")
                user_claim = debate_summary.get('user_claim_summary', '')
                key_conflict = debate_summary.get('key_conflict_point', '')

                # ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ã‚’ã€Œã‚ãªãŸã€ã«å¤‰æ›
                user_claim = user_claim.replace('ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯', 'ã‚ãªãŸã¯').replace('ãƒ¦ãƒ¼ã‚¶ãƒ¼', 'ã‚ãªãŸ')

                lines = [
                    "## ğŸ“Š è­°è«–åˆ†æçµæœ\n\n",
                    f"**{user_claim}**\n\n",
                    f"**ä¸»è¦ãªé•ã„**: {key_conflict}\n\n",
                    "---\n\n",
                    "ä¸Šè¨˜ã®åˆ†æã‚’è¸ã¾ãˆã¦ã€ã‚ãªãŸã®åˆ¤æ–­ç†ç”±ã«ã¤ã„ã¦è©³ã—ããŠèã‹ã›ãã ã•ã„ã€‚"
                ]

                initial_text = ''.join(lines)
                return [{"role": "assistant", "content": initial_text}]

        except Exception as e:
            print(f"[ERROR] åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã®è«–ç†ã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®é‡ã¿ç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    print(f"[DEBUG] ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨")
    criteria_order = ['å­¦æ¥­æˆç¸¾', 'åŸºç¤èƒ½åŠ›ãƒ†ã‚¹ãƒˆ', 'å®Ÿè·µçµŒé¨“', 'æ¨è–¦ãƒ»è©•ä¾¡', 'å¿—æœ›å‹•æ©Ÿãƒ»ãƒ•ã‚£ãƒƒãƒˆ']
    lines = [
        "ã€ã‚ãªãŸã®é‡è¦–ç‚¹ã«ã¤ã„ã¦ã€‘\n",
        "ç”»é¢ä¸Šã§è¨­å®šã•ã‚ŒãŸé‡ã¿é…åˆ†ã‚’ç¢ºèªã—ã¾ã—ãŸï¼š\n",
    ]

    for c in criteria_order:
        v = weights.get(c, 0)
        v = int(v) if isinstance(v, (int, float, str)) and str(v).isdigit() else 20
        lines.append(f"- {_display_label(c)}: {v}%\n")

    def _val_for(k: str) -> int:
        try:
            val = weights.get(k, 0)
            return int(val) if str(val).isdigit() else 0
        except Exception:
            return 0

    top = sorted([(k, _val_for(k)) for k in criteria_order], key=lambda kv: kv[1], reverse=True)
    top_name = _display_label(top[0][0]) if top else 'å­¦æ¥­æˆç¸¾'
    lines += [
        "\n",
        f"ã‚ãªãŸãŒç‰¹ã«{top_name}ã‚’é‡è¦–ã•ã‚Œã‚‹ç†ç”±ã«ã¤ã„ã¦ã€è©³ã—ããŠèã‹ã›ãã ã•ã„ã€‚\n",
        "ã“ã®å­¦ç”Ÿã®è©•ä¾¡ã«ãŠã„ã¦ãªãœã“ã‚Œã‚‰ã®é …ç›®ã‚’é‡è¦ã¨è€ƒãˆã‚‰ã‚ŒãŸã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ\n\n",
        "ãªãŠã€AI 3åã‚‚ãã‚Œãã‚Œç•°ãªã‚‹åŸºæº–ã‚’æŒã£ã¦è©•ä¾¡ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚",
    ]

    weights_text = ''.join(lines)
    return [{"role": "assistant", "content": weights_text}]


def _build_responses_input(messages: List[Dict[str, str]], system_text: str, context: Dict[str, Any]):
    # Streamlitç‰ˆã¨åŒã˜æ§‹é€ ã«å¤‰æ›ï¼ˆtypeã¯ input_text/output_textï¼‰
    input_seq: List[Dict] = [
        {"role": "system", "content": [{"type": "input_text", "text": system_text}]}
    ]

    safe_ctx = _sanitize_llm_context(context or {})
    decision_data_json = json.dumps(safe_ctx, ensure_ascii=False, indent=2)
    input_seq.append({
        "role": "system",
        "content": [{"type": "input_text", "text": "# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n" + decision_data_json}],
    })

    for idx, m in enumerate(messages):
        # åˆæœŸã®2ã¤ã®assistantãƒãƒ–ãƒ«ã¯LLMã¸ã¯æ¸¡ã•ãªã„
        if idx in (0, 1) and m.get("role") == "assistant":
            continue
        role = m.get("role", "user")
        ctype = "output_text" if role == "assistant" else "input_text"
        input_seq.append({"role": role, "content": [{"type": ctype, "text": m.get("content", "")}]} )

    return input_seq


def _call_llm(messages: List[Dict[str, str]], context: Dict[str, Any], model: str = "gpt-5-mini") -> str:
    client = _get_openai_client()
    system_text = _get_system_prompt()
    input_payload = _build_responses_input(messages, system_text, context)

    # AIã¸ã®å…¥åŠ›å…¨ä½“ã®æ–‡å­—æ•°ã‚’è¨ˆæ¸¬ã—ã¦ãƒ­ã‚°å‡ºåŠ›
    try:
        print(f"[AI_IO] AIå…¥åŠ›æ–‡å­—æ•°: {len(json.dumps(input_payload, ensure_ascii=False))}")
    except Exception:
        pass

    # Optional debug of payload
    try:
        if str(os.getenv('DEBUG_LLM_CONTEXT', '')).lower() in ('1', 'true', 'yes', 'on'):
            print("===== DEBUG: LLM INPUT PAYLOAD (truncated preview) =====")
            import itertools as _it
            # Print safely up to certain length
            import json as _json
            payload_str = _json.dumps(input_payload, ensure_ascii=False)
            print(payload_str[:4000] + ("..." if len(payload_str) > 4000 else ""))
            print("===== END PAYLOAD =====")
    except Exception:
        pass
    def _do_call(_client):
        print(f"[model]{model}")
        resp = _client.responses.create(
            model=model,
            input=input_payload,
            temperature=0.0,
            max_output_tokens=1024,
            top_p=1
        )
        text = getattr(resp, "output_text", None)
        if text:
            return text
        try:
            return resp.output[0].content[0].text  # type: ignore[attr-defined]
        except Exception:
            return str(resp)

    assistant_text = None

    # 1) ãƒ—ãƒ©ã‚¤ãƒãƒªã‚­ãƒ¼ã§å®Ÿè¡Œ
    try:
        assistant_text = _do_call(client)
    except Exception as primary_error:
        # 2) ã‚»ã‚«ãƒ³ãƒ€ãƒªã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚Œã°ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼
        api_key2 = os.getenv("OPENAI_API_KEY2")
        if api_key2:
            try:
                if str(os.getenv('DEBUG_LLM_CONTEXT', '')).lower() in ('1', 'true', 'yes', 'on'):
                    print("[LLM FAILOVER] ãƒ—ãƒ©ã‚¤ãƒãƒªå¤±æ•—ã€‚OPENAI_API_KEY2 ã§å†è©¦è¡Œã—ã¾ã™ã€‚")
                alt_client = _create_openai_client_with_key(api_key2)
                assistant_text = _do_call(alt_client)
            except Exception as secondary_error:
                # ã©ã¡ã‚‰ã‚‚å¤±æ•—ã—ãŸå ´åˆã¯ã€å…ƒã®ã‚¨ãƒ©ãƒ¼å†…å®¹ã¨ä½µã›ã¦ä¸Šã’ã‚‹
                raise RuntimeError(f"Primary OpenAI failed: {primary_error}; Secondary failed: {secondary_error}")
        else:
            # ã‚»ã‚«ãƒ³ãƒ€ãƒªãŒãªã„/åˆ©ç”¨ä¸å¯ãªã‚‰å…ƒã®ã‚¨ãƒ©ãƒ¼ã‚’ãã®ã¾ã¾
            raise

    if assistant_text is None:
        raise RuntimeError("AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    print(f"[AI_IO] AIå‡ºåŠ›æ–‡å­—æ•°: {len(assistant_text)}")

    return assistant_text


@ai_chat_bp.route('/setup_chat', methods=['POST'])
def setup_chat():
    """åˆæœŸ2ãƒãƒ–ãƒ«ã‚’ã‚µãƒ¼ãƒãƒ¼å´ã§ç”Ÿæˆã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿æŒ"""
    if 'session_id' not in session:
        return jsonify({'error': 'No session'}), 400

    data = request.get_json(silent=True) or {}
    weights = data.get('weights') or {}
    decision = data.get('decision', 'æœªå®š')

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¸ä¿å­˜ï¼ˆå¿…è¦ãªã‚‰ä»–ç”»é¢ã§ã‚‚å‚ç…§å¯ï¼‰
    session['user_weights'] = weights
    session['user_decision'] = decision

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ï¼ˆè«–ç†ã‚¨ãƒ³ã‚¸ãƒ³ç”¨ï¼‰
    def build_context() -> Dict[str, Any]:
        session_id = session['session_id']
        sdata = session_repository.get_session(session_id) or {}
        decision_data = sdata.get('decision_data', {})
        student = sdata.get('student_data') or session.get('student_info') or {}

        participant_opinions = decision_data.get('participant_opinions') or []
        participant_decisions = decision_data.get('participant_decisions') or []

        ctx = {
            'session_id': session_id,
            'student_info': student,
            'user_initial_decision': decision,
            'user_initial_weights': weights,
            'participant_decisions': participant_decisions,
            'participant_opinions': participant_opinions,
        }
        return ctx

    try:
        context = build_context()
        initial_msgs = _build_initial_messages(weights, context)
    except Exception as e:
        print(f"åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—ã§ç”Ÿæˆ
        initial_msgs = _build_initial_messages(weights)

    session['messages'] = list(initial_msgs)  # æ–°è¦é–‹å§‹
    session['conversation_count'] = 0

    return jsonify({'success': True, 'messages': initial_msgs})


@ai_chat_bp.route('/ai_chat', methods=['POST'])
def ai_chat():
    """LLMã¸ã®1ã‚¿ãƒ¼ãƒ³å•ã„åˆã‚ã›ï¼ˆStreamlitç›¸å½“ã®å…¥åŠ›æ–¹å¼ï¼‰"""
    if 'session_id' not in session:
        return jsonify({'error': 'No session'}), 400

    payload = request.get_json(silent=True) or {}
    user_message = (payload.get('message') or '').strip()
    if not user_message:
        return jsonify({'error': 'Empty message'}), 400

    # ä¼šè©±ãƒ¡ãƒ¢ãƒª
    messages: List[Dict[str, str]] = session.get('messages') or []
    if not messages:
        # æœªåˆæœŸåŒ–ã®å ´åˆã¯ç©ºã®åˆæœŸãƒãƒ–ãƒ«ã‚’ä½œã‚‹
        weights = session.get('user_weights', {})
        messages = _build_initial_messages(weights)

    messages.append({"role": "user", "content": user_message})

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³/DBã‹ã‚‰LLMç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
    def build_llm_context() -> Dict[str, Any]:
        session_id = session['session_id']
        sdata = session_repository.get_session(session_id) or {}
        decision_data = sdata.get('decision_data', {})
        questionnaire = sdata.get('questionnaire_data', {})
        student = sdata.get('student_data') or session.get('student_info') or {}

        # å‚åŠ è€…ã®æ±ºå®šã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³å›ºå®šå€¤ãŒã‚ã‚Œã°ãã‚Œã‚’åˆ©ç”¨
        participants = session.get('participant_decisions') or decision_data.get('participant_decisions') or []
        participant_opinions = decision_data.get('participant_opinions') or []
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæœ¬ä½“
        ctx: Dict[str, Any] = {
            'session_id': session_id,
            'condition': session.get('condition'),
            'trial': session.get('trial'),
            'student_info': student,
            'user_initial_decision': decision_data.get('user_decision') or session.get('user_decision'),
            'user_initial_weights': decision_data.get('user_weights') or session.get('user_weights') or {},
            'participant_decisions': participants,
            'participant_opinions': participant_opinions,
            'group_outcome': decision_data.get('group_outcome'),
            'questionnaire': questionnaire,
        }
        return ctx

    try:
        model = os.getenv('OPENAI_RESPONSES_MODEL', 'gpt-5-mini')
        ctx = build_llm_context()

        # === è«–ç†ã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã‚‹è­°è«–åˆ†æ ===
        try:
            # 1. è«–ç†ã‚¨ãƒ³ã‚¸ãƒ³ã‚’å®Ÿè¡Œã—ã¦ã€è­°è«–ã®æ§‹é€ ã‚’åˆ†æ
            arguments = argumentation_engine.extract_atomic_arguments(ctx)
            attacks = argumentation_engine.determine_attacks(arguments)

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é‡ã¿é…åˆ†ã‚’å–å¾—ï¼ˆæ–°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ç”¨ï¼‰
            user_weights = ctx.get('user_initial_weights') or ctx.get('user_final_weights') or {}

            # 2. æ–°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆ2æœ¬ç«‹ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°å‹ã‚µãƒªã‚¨ãƒ³ã‚¹ï¼‰ã‚’é©ç”¨
            if user_weights:
                debate_summary = argumentation_engine.summarize_debate(arguments, attacks, user_weights)
            else:
                # é‡ã¿æƒ…å ±ãŒãªã„å ´åˆã¯æ—¢å­˜ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨
                debate_summary = argumentation_engine.summarize_debate(arguments, attacks)

            # 3. åˆ†æçµæœã‚’LLMã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
            ctx['argumentation_analysis'] = debate_summary

            # 4. è­°è«–æ§‹é€ ã«åŸºã¥ãæ¨å¥¨è³ªå•ã‚‚ç”Ÿæˆ
            focused_question = argumentation_engine.generate_focused_question(debate_summary, messages)
            ctx['suggested_question'] = focused_question

            # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼ˆè«–ç†ã‚¨ãƒ³ã‚¸ãƒ³åˆ†æçµæœï¼‰
            if str(os.getenv('DEBUG_LLM_CONTEXT', '')).lower() in ('1', 'true', 'yes', 'on'):
                print("\n===== è«–ç†ã‚¨ãƒ³ã‚¸ãƒ³åˆ†æçµæœ =====")
                print(f"æŠ½å‡ºã•ã‚ŒãŸä¸»å¼µæ•°: {len(arguments)}")
                print(f"æ”»æ’ƒé–¢ä¿‚æ•°: {len(attacks)}")
                print(f"ä½¿ç”¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : {debate_summary.get('algorithm_type', 'legacy')}")
                print(f"è«–ç‚¹: {debate_summary.get('key_conflict_point', 'N/A')}")
                print(f"æ¨å¥¨è³ªå•: {focused_question}")
                if debate_summary.get('algorithm_type') == 'two_track_ranking_salience':
                    detailed = debate_summary.get('detailed_analysis', {})
                    print(f"æ¤œå‡ºã•ã‚ŒãŸå¯¾ç«‹ç‚¹æ•°: {len(detailed.get('conflict_points', []))}")
                print("===== åˆ†æçµæœçµ‚äº† =====\n")
        except Exception as analysis_error:
            print(f"è«–ç†ã‚¨ãƒ³ã‚¸ãƒ³åˆ†æã‚¨ãƒ©ãƒ¼: {analysis_error}")
            # åˆ†æå¤±æ•—æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åˆ†æçµæœã‚’è¨­å®š
            ctx['argumentation_analysis'] = {
                "key_conflict_point": "åˆ†æãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚",
                "user_claim_summary": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸»å¼µã‚’åˆ†æä¸­ã§ã™ã€‚"
            }

        # Debug print + persist last context (opt-in by env or always safe)
        try:
            if str(os.getenv('DEBUG_LLM_CONTEXT', '')).lower() in ('1', 'true', 'yes', 'on'):
                print("\n===== DEBUG: LLM CONTEXT (sanitized) =====")
                print(json.dumps(_sanitize_llm_context(ctx), ensure_ascii=False, indent=2))
                print("===== END CONTEXT =====\n")
        except Exception:
            pass

        # Save last context to DB for inspection in admin or scripts
        try:
            sdata = session_repository.get_session(session['session_id']) or {}
            ai_chat_data = sdata.get('ai_chat_data', {}) or {}
            ai_chat_data['last_llm_context'] = _sanitize_llm_context(ctx)
            session_repository.update_session(session['session_id'], ai_chat_data=ai_chat_data)
        except Exception:
            pass

        assistant_text = _call_llm(messages, ctx, model=model)
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

    messages.append({"role": "assistant", "content": assistant_text})
    session['messages'] = messages
    session['conversation_count'] = int(session.get('conversation_count', 0)) + 1

    # æ—¢å­˜ã®ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ä¿å­˜ï¼ˆç°¡æ˜“ï¼‰
    try:
        session_repository.save_ai_chat_turn(
            session_id=session['session_id'],
            turn=session['conversation_count'],
            user_message=user_message,
            ai_response=assistant_text,
            satisfaction_scores={},
            pj_state={}
        )
    except Exception:
        pass

    return jsonify({'success': True, 'message': assistant_text, 'turn': session['conversation_count']})


# äº’æ›ç”¨é€”ã®è»½é‡APIã¯ä¸è¦ã«ãªã£ãŸãŸã‚å‰Šé™¤


@ai_chat_bp.route('/chat_history')
def get_chat_history():
    """Retrieve chat history for current session"""
    if 'session_id' not in session:
        return jsonify({'error': 'No session'}), 400

    session_id = session['session_id']
    history = session_repository.get_ai_chat_history(session_id)

    return jsonify({
        'success': True,
        'history': history
    })


# LangGraphé–¢é€£ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯å‰Šé™¤


@ai_chat_bp.route('/reset_chat', methods=['POST'])
def reset_chat():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆLangGraphè¦ç´ ã¯ç ´æ£„ï¼‰"""
    if 'session_id' not in session:
        return jsonify({'error': 'No session'}), 400

    session.pop('messages', None)
    session['conversation_count'] = 0
    return jsonify({'success': True, 'message': 'Chat reset successfully'})
